{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В даному ноутбуці ми застосуємо методи регулярізації `L1` і `L2` до набору даних `Boston Housing` і порівняємо оцінку навчальної вибірки та оцінку тестової вибірки до та після використання цих методів."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = genfromtxt(\"https://raw.githubusercontent.com/m-mehdi/tutorials/main/boston_housing.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 1.80000000e-01, 6.78152493e-02, ...,\n",
       "        8.96799117e-02, 8.04248656e-03, 2.40000000e+01],\n",
       "       [2.35922539e-04, 0.00000000e+00, 2.42302053e-01, ...,\n",
       "        2.04470199e-01, 4.18080621e-02, 2.16000000e+01],\n",
       "       [2.35697744e-04, 0.00000000e+00, 2.42302053e-01, ...,\n",
       "        6.28144504e-02, 4.02790570e-03, 3.47000000e+01],\n",
       "       ...,\n",
       "       [6.11892474e-04, 0.00000000e+00, 4.20454545e-01, ...,\n",
       "        1.07891832e-01, 1.16406475e-02, 2.39000000e+01],\n",
       "       [1.16072990e-03, 0.00000000e+00, 4.20454545e-01, ...,\n",
       "        1.29930407e-01, 1.71795127e-02, 2.20000000e+01],\n",
       "       [4.61841693e-04, 0.00000000e+00, 4.20454545e-01, ...,\n",
       "        1.69701987e-01, 2.87987643e-02, 1.19000000e+01]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:,:-1]\n",
    "y = dataset[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тепер ми можемо навчити модель лінійної регресії, а потім подивитися оцінку навчального набору та результат тестового набору:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression-Training set score: 0.94\n",
      "Linear Regression-Test set score: 0.81\n"
     ]
    }
   ],
   "source": [
    "l_r = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "print(f\"Linear Regression-Training set score: {l_r.score(X_train, y_train):.2f}\")\n",
    "print(f\"Linear Regression-Test set score: {l_r.score(X_test, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Порівняння продуктивності моделі на навчальному наборі та тестовому наборі показує, що модель страждає від оверфітингу.\n",
    "\n",
    "Щоб уникнути оверфітингу та контролювати складність моделі, скористаємося `Ridge` регресією (регуляризація `L2`) і подивимося, наскільки добре це працює на наборі даних:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression-Training set score: 0.88\n",
      "Ridge Regression-Test set score: 0.84\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(alpha=0.7).fit(X_train, y_train)\n",
    "\n",
    "print(f\"Ridge Regression-Training set score: {ridge.score(X_train, y_train):.2f}\")\n",
    "print(f\"Ridge Regression-Test set score: {ridge.score(X_test, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Незважаючи на те, що оцінка навчального набору `Ridge` регресії трохи нижча, ніж оцінка навчальної лінійної регресії, оцінка тестового набору `Ridge` значно вища, ніж оцінка набору тесту лінійної регресії. Ці показники підтверджують, що `Ridge` регресія зменшує складність моделі.\n",
    "\n",
    "Параметр альфа визначає компроміс між продуктивністю моделі на навчальному наборі та її простотою. Таким чином, збільшення значення альфа (його значення за замовчуванням `1.0`) спрощує модель за рахунок скорочення коефіцієнтів.\n",
    "\n",
    "Тепер давайте застосуємо `LASSO`-регресію до набору даних і дослідимо результати."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression-Training set score: 0.25\n",
      "Lasso Regression-Test set score: 0.25\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso(alpha=1.0).fit(X_train, y_train)\n",
    "\n",
    "print(f\"Lasso Regression-Training set score: {lasso.score(X_train, y_train):.2f}\")\n",
    "print(f\"Lasso Regression-Test set score: {lasso.score(X_test, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Як бачимо, `LASSO` працює досить невтішно, і це ознака андерфітингу. Модель `LASSO` не працює добре, тому що більшість коефіцієнтів стали рівними нулю. Якщо ми хочемо знати точну кількість функцій, які були використані в моделі, ми можемо це подивитися:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 4\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of features: {sum(lasso.coef_ != 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Це означає, що лише `4` із `104` ознак у навчальному наборі використовуються в регресійній моделі `LASSO`, а решта ігноруються.\n",
    "\n",
    "Давайте відкоригуємо альфа, зменшивши його значення до `0.01`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression-Training set score: 0.88\n",
      "Lasso Regression-Test set score: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oleh_komenchuk/Developer/HillelIT/venv/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.339e+00, tolerance: 3.510e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso(alpha=0.01).fit(X_train, y_train)\n",
    "print(\"Lasso Regression-Training set score: {:.2f}\".format(lasso.score(X_train, y_train)))\n",
    "print(\"Lasso Regression-Test set score: {:.2f}\".format(lasso.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 30\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of features: {sum(lasso.coef_ != 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Повторний запуск коду вище показує, що зі зменшенням альфа модель Lasso використовує `30` із `104` функцій."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хоча ми можемо ще більше зменшити альфу, здається, що її оптимальне значення становить `0.01`.\n",
    "\n",
    "Остання техніка, яку ми будемо використовувати, це `Elastic Net`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic Net-Training set score: 0.91\n",
      "Elastic Net-Test set score: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oleh_komenchuk/Developer/HillelIT/venv/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.775e+03, tolerance: 3.510e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "elastic_net = ElasticNet(alpha=0.001, l1_ratio=0.7).fit(X_train, y_train)\n",
    "\n",
    "print(f\"Elastic Net-Training set score: {elastic_net.score(X_train, y_train):.2f}\")\n",
    "print(f\"Elastic Net-Test set score: {elastic_net.score(X_test, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
