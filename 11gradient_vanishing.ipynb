{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97c34677-ab2a-414c-b809-bcdd35027bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4a6211a-1d95-4bd7-b2b5-0a2685c46b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNet(nn.Module):\n",
    "    def __init__(self, nlayers: int):\n",
    "        super(DeepNet, self).__init__()\n",
    "        layers = []\n",
    "        for _ in range(nlayers):\n",
    "            layers.append(nn.Linear(10, 10))\n",
    "            layers.append(nn.Sigmoid())\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da3ffaef-1dc0-4ccb-b175-f318d16619cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)  # set random seed for reproducibility\n",
    "\n",
    "input_tensor = torch.randn(32, 10)\n",
    "target = torch.randn(32, 10)\n",
    "\n",
    "model = DeepNet(50)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8856205a-5171-4b7b-92f3-b62642ccdc9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/50 | Loss: 1.1513307094573975 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      " 2/50 | Loss: 1.15116286277771 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      " 3/50 | Loss: 1.1509954929351807 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      " 4/50 | Loss: 1.1508281230926514 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      " 5/50 | Loss: 1.150660753250122 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      " 6/50 | Loss: 1.1504935026168823 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      " 7/50 | Loss: 1.1503263711929321 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      " 8/50 | Loss: 1.150159478187561 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      " 9/50 | Loss: 1.14999258518219 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      "10/50 | Loss: 1.1498258113861084 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      "11/50 | Loss: 1.1496589183807373 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      "12/50 | Loss: 1.1494923830032349 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      "13/50 | Loss: 1.149325966835022 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      "14/50 | Loss: 1.1491596698760986 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      "15/50 | Loss: 1.1489933729171753 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      "16/50 | Loss: 1.1488271951675415 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      "17/50 | Loss: 1.1486608982086182 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      "18/50 | Loss: 1.1484951972961426 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      "19/50 | Loss: 1.148329257965088 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      "20/50 | Loss: 1.1481635570526123 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      "21/50 | Loss: 1.1479978561401367 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      "22/50 | Loss: 1.1478322744369507 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      "23/50 | Loss: 1.1476669311523438 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      "24/50 | Loss: 1.1475015878677368 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      "25/50 | Loss: 1.1473363637924194 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      "26/50 | Loss: 1.1471712589263916 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      "27/50 | Loss: 1.1470061540603638 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      "28/50 | Loss: 1.146841287612915 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      "29/50 | Loss: 1.1466765403747559 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      "30/50 | Loss: 1.1465117931365967 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      "31/50 | Loss: 1.146347165107727 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      "32/50 | Loss: 1.1461827754974365 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      "33/50 | Loss: 1.1460182666778564 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      "34/50 | Loss: 1.1458539962768555 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      "35/50 | Loss: 1.1456897258758545 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      "36/50 | Loss: 1.1455256938934326 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      "37/50 | Loss: 1.1453619003295898 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      "38/50 | Loss: 1.145197868347168 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      "39/50 | Loss: 1.1450341939926147 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      "40/50 | Loss: 1.1448705196380615 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      "41/50 | Loss: 1.1447069644927979 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      "42/50 | Loss: 1.1445435285568237 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      "43/50 | Loss: 1.1443802118301392 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      "44/50 | Loss: 1.1442168951034546 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      "45/50 | Loss: 1.1440536975860596 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      "46/50 | Loss: 1.1438907384872437 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      "47/50 | Loss: 1.1437276601791382 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      "48/50 | Loss: 1.1435649394989014 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      "49/50 | Loss: 1.143402338027954 | Average Gradient Magnitude: 2.802596928649634e-45\n",
      "50/50 | Loss: 1.1432397365570068 | Average Gradient Magnitude: 2.802596928649634e-45\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "for epoch in range(n_epochs):\n",
    "    # forward pass\n",
    "    outputs = model(input_tensor)\n",
    "    loss = criterion(outputs, target)\n",
    "\n",
    "    # backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # print the average gradient magnitude for the first layer\n",
    "    gradients = model.layers[0].weight.grad\n",
    "    avg_gradient_magnitude = gradients.abs().mean().item()\n",
    "    print(f\"{epoch+1:2d}/{n_epochs:2d} | Loss: {loss.item()} | Average Gradient Magnitude: {avg_gradient_magnitude}\")\n",
    "\n",
    "    # # Stop if gradients are vanishing\n",
    "    # if avg_gradient_magnitude < 1e-6:\n",
    "    #     print(\"Gradients are vanishing!\")\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d89a7de-80ea-45e0-a8f0-731bc7932886",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
